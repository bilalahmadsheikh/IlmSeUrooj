name: Verify Admission Deadlines

on:
  schedule:
    - cron: '0 0 1 * *'   # 1st of every month at midnight UTC
  workflow_dispatch:
    inputs:
      dry_run:
        description: 'Dry run (no commit/push)'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '20'
  NOTIFICATION_EMAIL: 'ba8516127@gmail.com'

permissions:
  contents: write

concurrency:
  group: verify-deadlines
  cancel-in-progress: true

jobs:
  verify-deadlines:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      has_changes: ${{ steps.check.outputs.has_changes }}
      scrape_status: ${{ steps.scrape.outcome }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4.1.1
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Python dependencies
        run: |
          pip install -r scripts/scrapers/requirements.txt
          playwright install chromium

      # ‚îÄ‚îÄ Backup current data before scraping ‚îÄ‚îÄ
      - name: Backup current data
        run: |
          cp src/data/universities.js src/data/universities.js.bak
          echo "‚úÖ Backed up current universities.js"

      # ‚îÄ‚îÄ Run scraper (continue-on-error so we can rollback) ‚îÄ‚îÄ
      - name: Run deadline verification scraper
        id: scrape
        continue-on-error: true
        run: |
          python scripts/scrapers/deadline_scraper.py 2>&1 | tee scrape_output.log

      # ‚îÄ‚îÄ Rollback on failure ‚îÄ‚îÄ
      - name: Rollback on failure (keep old data)
        if: steps.scrape.outcome == 'failure'
        run: |
          echo "‚ö†Ô∏è Scraper failed ‚Äî rolling back to previous data"
          cp src/data/universities.js.bak src/data/universities.js
          echo "‚úÖ Rollback complete ‚Äî old data preserved"

      # ‚îÄ‚îÄ Check for data changes ‚îÄ‚îÄ
      - name: Check for data changes
        id: check
        run: |
          if git diff --quiet src/data/universities.js; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi

      # ‚îÄ‚îÄ Generate detailed validation summary ‚îÄ‚îÄ
      - name: Generate validation summary
        if: always()
        run: |
          echo "## üìã Deadline Verification Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Date:** $(date -u '+%Y-%m-%d %H:%M UTC')" >> $GITHUB_STEP_SUMMARY
          echo "**Scraper Status:** ${{ steps.scrape.outcome == 'success' && '‚úÖ Success' || '‚ùå Failed' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Parse JSON report if it exists
          if [ -f reports/deadline-verification-report.json ]; then
            echo "### üìä Extraction Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Universities Scraped | $(jq '.universitiesScraped' reports/deadline-verification-report.json) |" >> $GITHUB_STEP_SUMMARY
            echo "| Failed Extractions | $(jq '.failedExtractions' reports/deadline-verification-report.json) |" >> $GITHUB_STEP_SUMMARY
            echo "| Dates Extracted | $(jq '.datesExtracted' reports/deadline-verification-report.json) |" >> $GITHUB_STEP_SUMMARY
            echo "| Data Changes | $(jq '.dataChanges' reports/deadline-verification-report.json) |" >> $GITHUB_STEP_SUMMARY
            echo "| Timestamps Updated | $(jq '.timestampsUpdated' reports/deadline-verification-report.json) |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Show changes if any
            CHANGES_COUNT=$(jq '.dataChanges' reports/deadline-verification-report.json)
            if [ "$CHANGES_COUNT" -gt 0 ] 2>/dev/null; then
              echo "### üîÑ Data Changes" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "| University | Field | Old Value | New Value |" >> $GITHUB_STEP_SUMMARY
              echo "|------------|-------|-----------|-----------|" >> $GITHUB_STEP_SUMMARY
              jq -r '.changes[] | "| \(.shortName) | \(.field) | \(.old) | \(.new) |"' reports/deadline-verification-report.json >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi

            # Show errors if any
            ERRORS_COUNT=$(jq '.failedExtractions' reports/deadline-verification-report.json)
            if [ "$ERRORS_COUNT" -gt 0 ] 2>/dev/null; then
              echo "### ‚ö†Ô∏è Failed Extractions" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "| University | Error |" >> $GITHUB_STEP_SUMMARY
              echo "|------------|-------|" >> $GITHUB_STEP_SUMMARY
              jq -r '.errors[] | "| \(.shortName) | \(.error) |"' reports/deadline-verification-report.json >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "### ‚ùå No report generated" >> $GITHUB_STEP_SUMMARY
            echo "The scraper did not produce a validation report." >> $GITHUB_STEP_SUMMARY
          fi

          # Rollback notice
          if [ "${{ steps.scrape.outcome }}" == "failure" ]; then
            echo "### üîô Rollback Applied" >> $GITHUB_STEP_SUMMARY
            echo "Scraper failed ‚Äî **old data has been preserved**. No changes were committed." >> $GITHUB_STEP_SUMMARY
          fi

      # ‚îÄ‚îÄ Upload report artifact ‚îÄ‚îÄ
      - name: Upload verification report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: deadline-verification-report
          path: |
            reports/deadline-verification-report.json
            scrape_output.log
          retention-days: 30

      # ‚îÄ‚îÄ Commit only on success with real changes ‚îÄ‚îÄ
      - name: Commit and push changes
        if: steps.scrape.outcome == 'success' && steps.check.outputs.has_changes == 'true' && !inputs.dry_run
        run: |
          git config user.name "IlmSeUrooj Bot"
          git config user.email "${{ env.NOTIFICATION_EMAIL }}"
          git add src/data/universities.js
          git commit -m "chore: Update admission deadlines [automated]

          $(if [ -f reports/deadline-verification-report.json ]; then
            echo "Universities scraped: $(jq '.universitiesScraped' reports/deadline-verification-report.json)"
            echo "Data changes: $(jq '.dataChanges' reports/deadline-verification-report.json)"
            echo "Dates extracted: $(jq '.datesExtracted' reports/deadline-verification-report.json)"
          fi)"
          git push

      # ‚îÄ‚îÄ Clean up backup ‚îÄ‚îÄ
      - name: Clean up backup
        if: always()
        run: rm -f src/data/universities.js.bak

  notify-on-failure:
    needs: [verify-deadlines]
    if: failure()
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Send failure notification
        continue-on-error: true
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          username: ${{ secrets.SMTP_USERNAME }}
          password: ${{ secrets.SMTP_PASSWORD }}
          subject: '‚ùå Deadline Verification Failed'
          to: ${{ env.NOTIFICATION_EMAIL }}
          from: IlmSeUrooj Bot
          body: |
            The deadline verification workflow has failed.
            Old data has been preserved (automatic rollback).

            Workflow: ${{ github.workflow }}
            Run ID: ${{ github.run_id }}

            Logs: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
